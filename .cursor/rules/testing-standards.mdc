---
globs: test_*.py,*_test.py,tests/**/*.py
---

# Testing Standards for Anomaly Detection API

## Test Structure Requirements

### 1. Test File Organization
- `tests/unit/` - Unit tests for individual components
- `tests/integration/` - API endpoint integration tests  
- `tests/performance/` - Load and performance tests
- `tests/fixtures/` - Test data and common setup

### 2. Essential Test Categories

#### Unit Tests (tests/unit/)
- `test_ml_algorithm.py` - Test [shared/models/anomaly/ml_model.py](mdc:shared/models/anomaly/ml_model.py)
  - Model training with various data patterns
  - Prediction accuracy validation
  - Edge cases (insufficient data, constant values, NaN)
  - Serialization/deserialization

- `test_training_service.py` - Test [services/training_service/main.py](mdc:services/training_service/main.py)
  - Training endpoint functionality
  - Database persistence
  - Model versioning
  - Error handling

- `test_inference_service.py` - Test [services/inference_service/main.py](mdc:services/inference_service/main.py)
  - Prediction endpoint functionality
  - Redis caching
  - Performance requirements
  - Cache miss handling

- `test_plot_service.py` - Test [services/plot_service/main.py](mdc:services/plot_service/main.py)
  - Data retrieval functionality
  - Version parameter handling
  - Database queries

- `test_services_simplified.py` - Test service endpoints with mocked dependencies
  - Isolated endpoint testing
  - Request/response validation

#### Integration Tests (tests/integration/)
- `test_end_to_end.py` - Test complete service integration
  - Cross-service workflows (train → predict → plot)
  - Database and Redis integration
  - Service communication
  - End-to-end data flow validation

#### Performance Tests (tests/performance/)
- `test_load.py` - Load testing against requirements
  - Target: 180 RPS sustained
  - P95 latency < 100ms
  - Concurrent training + inference

### 3. Test Data Requirements
Use real datasets from [dataset/](mdc:dataset/):
- Normal operating patterns
- Known anomaly scenarios
- Edge cases (constant values, sparse data)
- Different time series characteristics
- Shared fixtures in [tests/conftest.py](mdc:tests/conftest.py)

### 4. Performance Assertion Examples
```python
def test_inference_latency():
    # P95 latency must be < 100ms
    assert np.percentile(latencies, 95) < 0.1

def test_throughput():
    # Must handle 180+ RPS
    assert requests_per_second >= 180
```

### 5. Mock Strategy
- Mock external dependencies (PostgreSQL, Redis) in unit tests
- Use service-specific mocking per microservice
- Mock inter-service communication in isolated tests
- Use real infrastructure in integration tests
- Measure both scenarios for performance comparison