# ğŸ“Š Monitoramento e AnÃ¡lise de Performance

## ğŸ¯ MÃ©tricas Coletadas

### LatÃªncia
- **InferÃªncia Isolada**: Tempo gasto apenas na prediÃ§Ã£o
  - MÃ©trica: `inference_latency_seconds`
  - Labels: `series_id`, `model_version`
  - Target: P95 < 100ms

- **Logging Isolado**: Tempo gasto na persistÃªncia
  - MÃ©trica: `logging_latency_seconds`
  - Labels: `series_id`, `model_version`
  - AnÃ¡lise: Identificar impacto do logging

- **Total**: Tempo total da requisiÃ§Ã£o
  - MÃ©trica: `prediction_latency_seconds`
  - Labels: `series_id`, `model_version`
  - Target: P95 < 100ms

### Cache
- **Hit/Miss Rate**: EficiÃªncia do cache
  - MÃ©trica: `cache_operations_total`
  - Labels: `operation` (`hit`/`miss`), `series_id`
  - Target: Hit Rate > 80%

### Model Usage
- **PrediÃ§Ãµes**: Volume de uso por modelo
  - MÃ©trica: `model_predictions_total`
  - Labels: `series_id`, `model_version`, `is_anomaly`
  - Target: 180 RPS sustentado

### System Health
- **Active Models**: Modelos ativos no sistema
  - MÃ©trica: `active_models`
  - Labels: `series_id`

## ğŸ” Dashboards

### 1. Performance Overview
- LatÃªncia (P95, mÃ©dia) por modelo
- Throughput (RPS) por modelo
- Cache hit/miss rate
- Anomaly detection rate

### 2. System Health
- CPU/Memory por serviÃ§o
- Network I/O
- Disk usage
- Error rates

## ğŸš€ Como Usar

### Iniciar Monitoramento
```bash
# Na VM-6 (Monitoring)
cd monitoring
docker-compose up -d
```

### Acessar Dashboards
- **Grafana**: http://VM-6-IP:3000
  - User: admin
  - Pass: admin

### Executar Testes de Carga
```bash
# Instalar dependÃªncias
cd tests/performance
pip install -r requirements.txt

# Executar testes
python load_test.py
```

## ğŸ“ˆ AnÃ¡lise de Performance

### MÃ©tricas Principais
1. **LatÃªncia**
   - P95 < 100ms (requisito)
   - Breakdown: InferÃªncia vs. Logging
   - Alertas se P95 > 90ms

2. **Throughput**
   - Target: 180 RPS
   - Monitorar por `series_id`
   - Alertas se < 160 RPS

3. **Cache Efficiency**
   - Hit Rate > 80%
   - TTL: 1h para modelos
   - TTL: 5min para prediÃ§Ãµes

### Alertas Configurados
- P95 latÃªncia > 100ms
- Error rate > 1%
- Cache hit rate < 80%
- RPS < 160

## ğŸ”§ Troubleshooting

### Alta LatÃªncia
1. Verificar breakdown (inferÃªncia vs. logging)
2. Checar cache hit rate
3. Monitorar conexÃµes de banco
4. Verificar CPU/Memory

### Baixo Throughput
1. Verificar connection pool
2. Checar CPU/Memory
3. Monitorar network I/O
4. Validar cache size

### Cache Issues
1. Verificar Redis memory
2. Ajustar TTL se necessÃ¡rio
3. Monitorar eviction rate
4. Verificar key distribution

## ğŸ“ Logs

### Estrutura
```json
{
  "event": "prediction_metrics",
  "series_id": "sensor_123",
  "model_version": "v1",
  "latency_inference_ms": 45.2,
  "latency_logging_ms": 12.3,
  "latency_total_ms": 58.7,
  "cache_hit": true,
  "anomaly": false
}
```

### RetenÃ§Ã£o
- Prometheus: 15 dias
- Logs: 30 dias
- MÃ©tricas agregadas: 90 dias

## ğŸ”„ PrÃ³ximos Passos

1. **OtimizaÃ§Ã£o**
   - Se logging > 30% do tempo total:
     â†’ Implementar async queue
   - Se cache miss > 20%:
     â†’ Aumentar TTL ou cache size

2. **Escalabilidade**
   - Se RPS > 160:
     â†’ Adicionar rÃ©plicas
   - Se latÃªncia > 90ms P95:
     â†’ Otimizar queries/cache

3. **Monitoramento**
   - Adicionar tracing distribuÃ­do
   - Expandir mÃ©tricas de negÃ³cio
   - Criar dashboards por cliente
